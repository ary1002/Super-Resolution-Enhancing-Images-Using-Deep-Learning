{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82c5838f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T08:55:26.899096Z",
     "iopub.status.busy": "2023-12-13T08:55:26.898670Z",
     "iopub.status.idle": "2023-12-13T08:55:48.278584Z",
     "shell.execute_reply": "2023-12-13T08:55:48.277359Z"
    },
    "papermill": {
     "duration": 21.387892,
     "end_time": "2023-12-13T08:55:48.281487",
     "exception": false,
     "start_time": "2023-12-13T08:55:26.893595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations in /opt/conda/lib/python3.10/site-packages (1.3.1)\r\n",
      "Requirement already satisfied: numpy>=1.11.1 in /opt/conda/lib/python3.10/site-packages (from albumentations) (1.24.3)\r\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from albumentations) (1.11.4)\r\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /opt/conda/lib/python3.10/site-packages (from albumentations) (0.21.0)\r\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from albumentations) (6.0.1)\r\n",
      "Requirement already satisfied: qudida>=0.0.4 in /opt/conda/lib/python3.10/site-packages (from albumentations) (0.0.4)\r\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from albumentations) (4.8.1.78)\r\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/lib/python3.10/site-packages (from qudida>=0.0.4->albumentations) (1.2.2)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from qudida>=0.0.4->albumentations) (4.5.0)\r\n",
      "Requirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (3.1)\r\n",
      "Requirement already satisfied: pillow>=9.0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (10.1.0)\r\n",
      "Requirement already satisfied: imageio>=2.27 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (2.31.1)\r\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (2023.8.12)\r\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (1.4.1)\r\n",
      "Requirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (21.3)\r\n",
      "Requirement already satisfied: lazy_loader>=0.2 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.16.1->albumentations) (0.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21->scikit-image>=0.16.1->albumentations) (3.0.9)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.3.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install albumentations\n",
    "import torch\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "#from tqdm import tqdm\n",
    "import time\n",
    "import torch.nn\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "LOAD_MODEL = True\n",
    "SAVE_MODEL = True\n",
    "CHECKPOINT_GEN = \"/kaggle/input/saved-models500e/gen.pth\"\n",
    "CHECKPOINT_DISC = \"/kaggle/input/saved-models500e/disc.pth\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 16\n",
    "LAMBDA_GP = 10\n",
    "NUM_WORKERS = 4\n",
    "HIGH_RES = 128\n",
    "LOW_RES = HIGH_RES // 4\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "highres_transform = A.Compose(\n",
    "    [\n",
    "        A.Normalize(mean=[0, 0, 0], std=[1, 1, 1]),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "lowres_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(width=LOW_RES, height=LOW_RES, interpolation=Image.BICUBIC),\n",
    "        A.Normalize(mean=[0, 0, 0], std=[1, 1, 1]),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "both_transforms = A.Compose(\n",
    "    [\n",
    "        A.RandomCrop(width=HIGH_RES, height=HIGH_RES),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "    ]\n",
    ")\n",
    "test_transform = A.Compose(\n",
    "    [\n",
    "        A.Normalize(mean=[0, 0, 0], std=[1, 1, 1]),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a08eb862",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T08:55:48.291073Z",
     "iopub.status.busy": "2023-12-13T08:55:48.290509Z",
     "iopub.status.idle": "2023-12-13T08:55:51.344800Z",
     "shell.execute_reply": "2023-12-13T08:55:51.343651Z"
    },
    "papermill": {
     "duration": 3.062093,
     "end_time": "2023-12-13T08:55:51.347408",
     "exception": false,
     "start_time": "2023-12-13T08:55:48.285315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 96, 96])\n",
      "torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, use_act, **kwargs):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            **kwargs,\n",
    "            bias=True,\n",
    "        )\n",
    "        self.act = nn.LeakyReLU(0.2, inplace=True) if use_act else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.cnn(x))\n",
    "\n",
    "\n",
    "class UpsampleBlock(nn.Module):\n",
    "    def __init__(self, in_c, scale_factor=2):\n",
    "        super().__init__()\n",
    "        self.upsample = nn.Upsample(scale_factor=scale_factor, mode=\"nearest\")\n",
    "        self.conv = nn.Conv2d(in_c, in_c, 3, 1, 1, bias=True)\n",
    "        self.act = nn.LeakyReLU(0.2, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.conv(self.upsample(x)))\n",
    "\n",
    "\n",
    "class DenseResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, channels=32, residual_beta=0.2):\n",
    "        super().__init__()\n",
    "        self.residual_beta = residual_beta\n",
    "        self.blocks = nn.ModuleList()\n",
    "\n",
    "        for i in range(5):\n",
    "            self.blocks.append(\n",
    "                ConvBlock(\n",
    "                    in_channels + channels * i,\n",
    "                    channels if i <= 3 else in_channels,\n",
    "                    kernel_size=3,\n",
    "                    stride=1,\n",
    "                    padding=1,\n",
    "                    use_act=True if i <= 3 else False,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        new_inputs = x\n",
    "        for block in self.blocks:\n",
    "            out = block(new_inputs)\n",
    "            new_inputs = torch.cat([new_inputs, out], dim=1)\n",
    "        return self.residual_beta * out + x\n",
    "\n",
    "\n",
    "class RRDB(nn.Module):\n",
    "    def __init__(self, in_channels, residual_beta=0.2):\n",
    "        super().__init__()\n",
    "        self.residual_beta = residual_beta\n",
    "        self.rrdb = nn.Sequential(*[DenseResidualBlock(in_channels) for _ in range(3)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.rrdb(x) * self.residual_beta + x\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_channels=64, num_blocks=23):\n",
    "        super().__init__()\n",
    "        self.initial = nn.Conv2d(\n",
    "            in_channels,\n",
    "            num_channels,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            bias=True,\n",
    "        )\n",
    "        self.residuals = nn.Sequential(*[RRDB(num_channels) for _ in range(num_blocks)])\n",
    "        self.conv = nn.Conv2d(num_channels, num_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.upsamples = nn.Sequential(\n",
    "            UpsampleBlock(num_channels), UpsampleBlock(num_channels),\n",
    "        )\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(num_channels, num_channels, 3, 1, 1, bias=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(num_channels, in_channels, 3, 1, 1, bias=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        initial = self.initial(x)\n",
    "        x = self.conv(self.residuals(initial)) + initial\n",
    "        x = self.upsamples(x)\n",
    "        return self.final(x)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3, features=[64, 64, 128, 128, 256, 256, 512, 512]):\n",
    "        super().__init__()\n",
    "        blocks = []\n",
    "        for idx, feature in enumerate(features):\n",
    "            blocks.append(\n",
    "                ConvBlock(\n",
    "                    in_channels,\n",
    "                    feature,\n",
    "                    kernel_size=3,\n",
    "                    stride=1 + idx % 2,\n",
    "                    padding=1,\n",
    "                    use_act=True,\n",
    "                ),\n",
    "            )\n",
    "            in_channels = feature\n",
    "\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((6, 6)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512 * 6 * 6, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.blocks(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "def initialize_weights(model, scale=0.1):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            nn.init.kaiming_normal_(m.weight.data)\n",
    "            m.weight.data *= scale\n",
    "\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_normal_(m.weight.data)\n",
    "            m.weight.data *= scale\n",
    "\n",
    "\n",
    "def test():\n",
    "    gen = Generator()\n",
    "    disc = Discriminator()\n",
    "    low_res = 24\n",
    "    x = torch.randn((5, 3, low_res, low_res))\n",
    "    gen_out = gen(x)\n",
    "    disc_out = disc(gen_out)\n",
    "\n",
    "    print(gen_out.shape)\n",
    "    print(disc_out.shape)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3c86637",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T08:55:51.356368Z",
     "iopub.status.busy": "2023-12-13T08:55:51.356003Z",
     "iopub.status.idle": "2023-12-13T08:55:51.371713Z",
     "shell.execute_reply": "2023-12-13T08:55:51.370622Z"
    },
    "papermill": {
     "duration": 0.023059,
     "end_time": "2023-12-13T08:55:51.374142",
     "exception": false,
     "start_time": "2023-12-13T08:55:51.351083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "\n",
    "\n",
    "def gradient_penalty(critic, real, fake, device):\n",
    "    BATCH_SIZE, C, H, W = real.shape\n",
    "    alpha = torch.rand((BATCH_SIZE, 1, 1, 1)).repeat(1, C, H, W).to(device)\n",
    "    interpolated_images = real * alpha + fake.detach() * (1 - alpha)\n",
    "    interpolated_images.requires_grad_(True)\n",
    "\n",
    "    # Calculate critic scores\n",
    "    mixed_scores = critic(interpolated_images)\n",
    "\n",
    "    # Take the gradient of the scores with respect to the images\n",
    "    gradient = torch.autograd.grad(\n",
    "        inputs=interpolated_images,\n",
    "        outputs=mixed_scores,\n",
    "        grad_outputs=torch.ones_like(mixed_scores),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "    gradient = gradient.view(gradient.shape[0], -1)\n",
    "    gradient_norm = gradient.norm(2, dim=1)\n",
    "    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n",
    "    return gradient_penalty\n",
    "\n",
    "\n",
    "def save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    checkpoint = {\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(checkpoint, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint_file, model, optimizer, lr):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    checkpoint = torch.load(checkpoint_file, map_location=DEVICE)\n",
    "    # model.load_state_dict(checkpoint)\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "\n",
    "    # If we don't do this then it will just have learning rate of old checkpoint\n",
    "    # and it will lead to many hours of debugging \\:\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr\n",
    "\n",
    "\n",
    "def plot_examples(low_res_folder, gen):\n",
    "    files = os.listdir(low_res_folder)\n",
    "\n",
    "    gen.eval()\n",
    "    for file in files:\n",
    "        image=Image.open(os.path.join(low_res_folder, file))\n",
    "        with torch.no_grad():\n",
    "            upscaled_img = gen(\n",
    "                test_transform(image=np.asarray(image))[\"image\"]\n",
    "                .unsqueeze(0)\n",
    "                .to(DEVICE)\n",
    "            )\n",
    "        save_image(upscaled_img, os.path.join(\"/kaggle/working/\", file))\n",
    "    gen.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eae8cf81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T08:55:51.382970Z",
     "iopub.status.busy": "2023-12-13T08:55:51.382559Z",
     "iopub.status.idle": "2023-12-13T08:56:11.663754Z",
     "shell.execute_reply": "2023-12-13T08:56:11.662364Z"
    },
    "papermill": {
     "duration": 20.288649,
     "end_time": "2023-12-13T08:56:11.666637",
     "exception": false,
     "start_time": "2023-12-13T08:55:51.377988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading checkpoint\n"
     ]
    }
   ],
   "source": [
    "gen = Generator(in_channels=3).to(DEVICE)\n",
    "opt_gen = torch.optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.9))\n",
    "load_checkpoint(\n",
    "    CHECKPOINT_GEN,\n",
    "    gen,\n",
    "    opt_gen,\n",
    "    LEARNING_RATE,\n",
    ")\n",
    "plot_examples(\"/kaggle/input/low-res\",gen)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4157520,
     "sourceId": 7190382,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4157609,
     "sourceId": 7190494,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30615,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 49.414268,
   "end_time": "2023-12-13T08:56:12.893158",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-13T08:55:23.478890",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
